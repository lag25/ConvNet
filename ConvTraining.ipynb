{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e49ce9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1457d047",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 128, 128, 16)      160       \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 128, 128, 16)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 64)        4160      \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 4, 4, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 6150      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,470\n",
      "Trainable params: 10,470\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers as tfl\n",
    "def convolutional_model(input_shape):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    conv_layer1 = tfl.Conv2D(filters = 16 , kernel_size= 3 , strides= 1 , padding='same')(input_img)\n",
    "    activation1 = tfl.ReLU()(conv_layer1)\n",
    "    pool_layer1 = tfl.MaxPool2D(pool_size=8, strides=8, padding='same')(activation1)\n",
    "    conv_layer2 = tfl.Conv2D(filters= 64 , kernel_size= 2 , strides= 1 , padding='same')(pool_layer1)\n",
    "    activation2 = tfl.ReLU()(conv_layer2)\n",
    "    pool_layer2 = tfl.MaxPool2D(pool_size=4, strides=4, padding='same')(activation2)\n",
    "    flatten =  tfl.Flatten()(pool_layer2)\n",
    "    outputs =  tfl.Dense(6, activation='softmax')(flatten)\n",
    "    model = tf.keras.Model(inputs=input_img, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((128, 128, 1))\n",
    "conv_model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c11af4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=40,rescale=1./255,width_shift_range=0.2,\n",
    "        height_shift_range=0.2,shear_range=0.2,\n",
    "        zoom_range=0.4,brightness_range=[0.4,1.5])\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=40,rescale=1./255,width_shift_range=0.2,\n",
    "        height_shift_range=0.2,shear_range=0.2,\n",
    "        zoom_range=0.4,brightness_range=[0.4,1.5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87d11c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir_new = \"C:/Users/91898/Desktop/Finger Counting/Finger_Classes\"\n",
    "test_dir_new = \"C:/Users/91898/Desktop/Finger Counting/Finger_Classes_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70474948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18085 images belonging to 6 classes.\n",
      "Found 3600 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_dir_new,\n",
    "                                                   target_size = (128,128), batch_size = 32 , class_mode='categorical',color_mode='grayscale')\n",
    "test_generator = test_datagen.flow_from_directory(test_dir_new,\n",
    "                                                   target_size = (128,128), batch_size = 32 , class_mode='categorical',color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27322941",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-1486996ba1cb>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model = conv_model.fit_generator(train_generator,steps_per_epoch=200,epochs=75,shuffle=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "200/200 [==============================] - 22s 106ms/step - loss: 1.7408 - accuracy: 0.2430\n",
      "Epoch 2/75\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 1.5171 - accuracy: 0.3841\n",
      "Epoch 3/75\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 1.2792 - accuracy: 0.4934\n",
      "Epoch 4/75\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 1.1509 - accuracy: 0.5480\n",
      "Epoch 5/75\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 1.0530 - accuracy: 0.5859\n",
      "Epoch 6/75\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 1.0110 - accuracy: 0.5958\n",
      "Epoch 7/75\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.9544 - accuracy: 0.6239\n",
      "Epoch 8/75\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 0.9231 - accuracy: 0.6381\n",
      "Epoch 9/75\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.9046 - accuracy: 0.6628\n",
      "Epoch 10/75\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.8363 - accuracy: 0.6789\n",
      "Epoch 11/75\n",
      "200/200 [==============================] - 17s 82ms/step - loss: 0.8248 - accuracy: 0.6835\n",
      "Epoch 12/75\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.7836 - accuracy: 0.7022\n",
      "Epoch 13/75\n",
      "200/200 [==============================] - 18s 90ms/step - loss: 0.7458 - accuracy: 0.7252\n",
      "Epoch 14/75\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.7299 - accuracy: 0.7253\n",
      "Epoch 15/75\n",
      "200/200 [==============================] - 18s 87ms/step - loss: 0.6837 - accuracy: 0.7466\n",
      "Epoch 16/75\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.6719 - accuracy: 0.7538\n",
      "Epoch 17/75\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.6543 - accuracy: 0.7575\n",
      "Epoch 18/75\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.6348 - accuracy: 0.7678\n",
      "Epoch 19/75\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.6193 - accuracy: 0.7731\n",
      "Epoch 20/75\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.5917 - accuracy: 0.7825\n",
      "Epoch 21/75\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.5945 - accuracy: 0.7794\n",
      "Epoch 22/75\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.5739 - accuracy: 0.8001\n",
      "Epoch 23/75\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.5782 - accuracy: 0.7978\n",
      "Epoch 24/75\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.5800 - accuracy: 0.7916\n",
      "Epoch 25/75\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.5563 - accuracy: 0.8092\n",
      "Epoch 26/75\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.5320 - accuracy: 0.8134\n",
      "Epoch 27/75\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.5128 - accuracy: 0.8128\n",
      "Epoch 28/75\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.5141 - accuracy: 0.8214\n",
      "Epoch 29/75\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.5115 - accuracy: 0.8169\n",
      "Epoch 30/75\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.5183 - accuracy: 0.8186\n",
      "Epoch 31/75\n",
      "200/200 [==============================] - 18s 91ms/step - loss: 0.4989 - accuracy: 0.8245\n",
      "Epoch 32/75\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.4959 - accuracy: 0.8289\n",
      "Epoch 33/75\n",
      "200/200 [==============================] - 18s 89ms/step - loss: 0.4886 - accuracy: 0.8316\n",
      "Epoch 34/75\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 0.4865 - accuracy: 0.8273\n",
      "Epoch 35/75\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.4544 - accuracy: 0.8426\n",
      "Epoch 36/75\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 0.4782 - accuracy: 0.8336\n",
      "Epoch 37/75\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 0.4884 - accuracy: 0.8327\n",
      "Epoch 38/75\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 0.4447 - accuracy: 0.8437\n",
      "Epoch 39/75\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 0.4705 - accuracy: 0.8354\n",
      "Epoch 40/75\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 0.4542 - accuracy: 0.8453\n",
      "Epoch 41/75\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.4369 - accuracy: 0.8570\n",
      "Epoch 42/75\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 0.4547 - accuracy: 0.8462\n",
      "Epoch 43/75\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 0.4448 - accuracy: 0.8464\n",
      "Epoch 44/75\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.4247 - accuracy: 0.8605\n",
      "Epoch 45/75\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 0.4491 - accuracy: 0.8461\n",
      "Epoch 46/75\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 0.4077 - accuracy: 0.8583\n",
      "Epoch 47/75\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 0.4196 - accuracy: 0.8641\n",
      "Epoch 48/75\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 0.4179 - accuracy: 0.8498\n",
      "Epoch 49/75\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.3972 - accuracy: 0.8636\n",
      "Epoch 50/75\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 0.3910 - accuracy: 0.8616\n",
      "Epoch 51/75\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 0.4284 - accuracy: 0.8591\n",
      "Epoch 52/75\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 0.3895 - accuracy: 0.8708\n",
      "Epoch 53/75\n",
      "200/200 [==============================] - 17s 82ms/step - loss: 0.3982 - accuracy: 0.8648\n",
      "Epoch 54/75\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 0.4013 - accuracy: 0.8674\n",
      "Epoch 55/75\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.3671 - accuracy: 0.8778\n",
      "Epoch 56/75\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.4024 - accuracy: 0.8644\n",
      "Epoch 57/75\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 0.4161 - accuracy: 0.8619\n",
      "Epoch 58/75\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.3812 - accuracy: 0.8712\n",
      "Epoch 59/75\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.4057 - accuracy: 0.8661\n",
      "Epoch 60/75\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.4121 - accuracy: 0.8652\n",
      "Epoch 61/75\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 0.3667 - accuracy: 0.8805\n",
      "Epoch 62/75\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.3827 - accuracy: 0.8775\n",
      "Epoch 63/75\n",
      "200/200 [==============================] - 17s 87ms/step - loss: 0.3529 - accuracy: 0.8881\n",
      "Epoch 64/75\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.3731 - accuracy: 0.8786\n",
      "Epoch 65/75\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 0.3523 - accuracy: 0.8867\n",
      "Epoch 66/75\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.3574 - accuracy: 0.8803\n",
      "Epoch 67/75\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.3585 - accuracy: 0.8756\n",
      "Epoch 68/75\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.3389 - accuracy: 0.8922\n",
      "Epoch 69/75\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.3541 - accuracy: 0.8931\n",
      "Epoch 70/75\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.3693 - accuracy: 0.8852\n",
      "Epoch 71/75\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.3496 - accuracy: 0.8856\n",
      "Epoch 72/75\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.3622 - accuracy: 0.8866\n",
      "Epoch 73/75\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.3499 - accuracy: 0.8909\n",
      "Epoch 74/75\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.3645 - accuracy: 0.8847\n",
      "Epoch 75/75\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.3243 - accuracy: 0.8938\n"
     ]
    }
   ],
   "source": [
    "model = conv_model.fit_generator(train_generator,steps_per_epoch=200,epochs=75,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b75ba794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(img_address):\n",
    "    import cv2 \n",
    "    img = cv2.imread(img_address)\n",
    "    image = cv2.resize(img,(128,128))\n",
    "    return image\n",
    "\n",
    "def grayscale(image_address):\n",
    "    from skimage import io,color\n",
    "    \n",
    "    image = color.rgb2gray(image_address)\n",
    "    io.imshow(image)\n",
    "        \n",
    "    \n",
    "    return image\n",
    "\n",
    "def gauss(img):\n",
    "    mean = 0\n",
    "    var = 0.1\n",
    "    sigma = var ** 0.5\n",
    "    gaussian = np.random.normal(mean,var,(128, 128)) #  np.zeros((224, 224), np.float32)\n",
    "    pareto = np.random.pareto(40,(128,128))\n",
    "    poisson = np.random.poisson(0.003,(128,128))\n",
    "    \n",
    "    noisy_image = np.zeros(img.shape, np.float32)\n",
    "\n",
    "    if len(img.shape) == 2:\n",
    "        noisy_image = img+pareto\n",
    "    else:\n",
    "        noisy_image[:, :, 0] = img[:, :, 0] + gaussian\n",
    "        noisy_image[:, :, 1] = img[:, :, 1] + gaussian\n",
    "        noisy_image[:, :, 2] = img[:, :, 2] + gaussian\n",
    "\n",
    "    cv2.normalize(noisy_image, noisy_image, 0, 255, cv2.NORM_MINMAX, dtype=-1)\n",
    "    noisy_image = noisy_image.astype(np.uint8)\n",
    "    \n",
    "    plt.imshow(noisy_image,cmap='gray')\n",
    "    \n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64aeb2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_address=r\"C:/Users/91898/Downloads/Showing_1.png\"\n",
    "img = resize(image_address)\n",
    "\n",
    "image = grayscale(img)\n",
    "#image = gauss(image)\n",
    "image = np.expand_dims(image,0)\n",
    "len(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8089eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = conv_model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c297b623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_user_pred(arr,var=0):\n",
    "    for a in range(len(arr[0])):\n",
    "        if arr[0][a]>var:\n",
    "            var = arr[0][a]\n",
    "            index = a \n",
    "    return index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "778e1be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(give_user_pred(pred))  #FINAL PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ad76c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
